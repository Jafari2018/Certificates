{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9eoUpAsw7NukTQ8BYOvNM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jafari2018/Certificates/blob/main/Basics%20of%20PyTorch3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNmHDxoROpWs"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "!pip install pandas --quiet\n",
        "# Imports\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Figure Settings\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').disabled = True\n",
        "\n",
        "import ipywidgets as widgets\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")"
      ],
      "metadata": {
        "id": "Juulrd2fWnSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting functions\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "def ex3_plot(model, x, y, ep, lss):\n",
        "  \"\"\"\n",
        "  Plot training loss\n",
        "\n",
        "  Args:\n",
        "    model: nn.module\n",
        "      Model implementing regression\n",
        "    x: np.ndarray\n",
        "      Training Data\n",
        "    y: np.ndarray\n",
        "      Targets\n",
        "    ep: int\n",
        "      Number of epochs\n",
        "    lss: function\n",
        "      Loss function\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "  ax1.set_title(\"Regression\")\n",
        "  ax1.plot(x, model(x).detach().numpy(), color='r', label='prediction')\n",
        "  ax1.scatter(x, y, c='c', label='targets')\n",
        "  ax1.set_xlabel('x')\n",
        "  ax1.set_ylabel('y')\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2.set_title(\"Training loss\")\n",
        "  ax2.plot(np.linspace(1, epochs, epochs), losses, color='y')\n",
        "  ax2.set_xlabel(\"Epoch\")\n",
        "  ax2.set_ylabel(\"MSE\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def ex1_plot(fun_z, fun_dz):\n",
        "  \"\"\"\n",
        "  Plots the function and gradient vectors\n",
        "\n",
        "  Args:\n",
        "    fun_z: f.__name__\n",
        "      Function implementing sine function\n",
        "    fun_dz: f.__name__\n",
        "      Function implementing sine function as gradient vector\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  x, y = np.arange(-3, 3.01, 0.02), np.arange(-3, 3.01, 0.02)\n",
        "  xx, yy = np.meshgrid(x, y, sparse=True)\n",
        "  zz = fun_z(xx, yy)\n",
        "  xg, yg = np.arange(-2.5, 2.6, 0.5), np.arange(-2.5, 2.6, 0.5)\n",
        "  xxg, yyg = np.meshgrid(xg, yg, sparse=True)\n",
        "  zxg, zyg = fun_dz(xxg, yyg)\n",
        "\n",
        "  plt.figure(figsize=(8, 7))\n",
        "  plt.title(\"Gradient vectors point towards steepest ascent\")\n",
        "  contplt = plt.contourf(x, y, zz, levels=20)\n",
        "  plt.quiver(xxg, yyg, zxg, zyg, scale=50, color='r', )\n",
        "  plt.xlabel('$x$')\n",
        "  plt.ylabel('$y$')\n",
        "  ax = plt.gca()\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  cbar = plt.colorbar(contplt, cax=cax)\n",
        "  cbar.set_label('$z = h(x, y)$')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "FNj1WuXf0dEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# For DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ],
      "metadata": {
        "id": "upCHfIUd0yVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"GPU is not enabled in this notebook. \\n\"\n",
        "          \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
        "          \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook. \\n\"\n",
        "          \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
        "          \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
        "\n",
        "  return device\n",
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()\n"
      ],
      "metadata": {
        "id": "EL22hk6t0_Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper Functions\n",
        "\n",
        "def checkExercise1(A, B, C, D):\n",
        "  \"\"\"\n",
        "  Helper function for checking Exercise 1.\n",
        "\n",
        "  Args:\n",
        "    A: torch.Tensor\n",
        "      Torch Tensor of shape (20, 21) consisting of ones.\n",
        "    B: torch.Tensor\n",
        "      Torch Tensor of size([3,4])\n",
        "    C: torch.Tensor\n",
        "      Torch Tensor of size([20,21])\n",
        "    D: torch.Tensor\n",
        "      Torch Tensor of size([19])\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  assert torch.equal(A.to(int),torch.ones(20, 21).to(int)), \"Got: {A} \\n Expected: {torch.ones(20, 21)} (shape: {torch.ones(20, 21).shape})\"\n",
        "  assert np.array_equal(B.numpy(),np.vander([1, 2, 3], 4)), \"Got: {B} \\n Expected: {np.vander([1, 2, 3], 4)} (shape: {np.vander([1, 2, 3], 4).shape})\"\n",
        "  assert C.shape == (20, 21), \"Got: {C} \\n Expected (shape: {(20, 21)})\"\n",
        "  assert torch.equal(D, torch.arange(4, 41, step=2)), \"Got {D} \\n Expected: {torch.arange(4, 41, step=2)} (shape: {torch.arange(4, 41, step=2).shape})\"\n",
        "  print(\"All correct\")\n",
        "\n",
        "def timeFun(f, dim, iterations, device='cpu'):\n",
        "  \"\"\"\n",
        "  Helper function to calculate amount of time taken per instance on CPU/GPU\n",
        "\n",
        "  Args:\n",
        "    f: BufferedReader IO instance\n",
        "      Function name for which to calculate computational time complexity\n",
        "    dim: Integer\n",
        "      Number of dimensions in instance in question\n",
        "    iterations: Integer\n",
        "      Number of iterations for instance in question\n",
        "    device: String\n",
        "      Device on which respective computation is to be run\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  iterations = iterations\n",
        "  t_total = 0\n",
        "  for _ in range(iterations):\n",
        "    start = time.time()\n",
        "    f(dim, device)\n",
        "    end = time.time()\n",
        "    t_total += end - start\n",
        "\n",
        "  if device == 'cpu':\n",
        "    print(f\"time taken for {iterations} iterations of {f.__name__}({dim}, {device}): {t_total:.5f}\")\n",
        "  else:\n",
        "    print(f\"time taken for {iterations} iterations of {f.__name__}({dim}, {device}): {t_total:.5f}\")"
      ],
      "metadata": {
        "id": "oea7MN3BvWCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can construct a tensor directly from some common python iterables,\n",
        "# such as list and tuple nested iterables can also be handled as long as the\n",
        "# dimensions are compatible\n",
        "\n",
        "# tensor from a list\n",
        "a = torch.tensor([0, 1, 2])\n",
        "#tensor from a tuple of tuples\n",
        "b = ((1.0, 1.1), (1.2, 1.3))\n",
        "b = torch.tensor(b)\n",
        "# tensor from a numpy array\n",
        "c = np.ones([2, 3])\n",
        "c = torch.tensor(c)\n",
        "print(f\"Tensor a: {a}\")\n",
        "print(f\"Tensor b: {b}\")\n",
        "print(f\"Tensor c: {c}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI4aGofAJ2Hm",
        "outputId": "a4a0f90c-e997-466f-a07f-ccb09a23dfd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([0, 1, 2])\n",
            "Tensor b: tensor([[1.0000, 1.1000],\n",
            "        [1.2000, 1.3000]])\n",
            "Tensor c: tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, 3)\n",
        "y = torch.zeros(2)\n",
        "z = torch.empty(1, 1, 5)\n",
        "print(f\"Tensor x: {x}\")\n",
        "print(f\"Tensor y: {y}\")\n",
        "print(f\"Tensor z: {z}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dn_XzAaLasb",
        "outputId": "37fe89bf-343d-4176-ce3f-b3d1193185c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor x: tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Tensor y: tensor([0., 0.])\n",
            "Tensor z: tensor([[[2.1500e-15, 4.5622e-41, 5.6588e-34, 0.0000e+00, 4.4842e-44]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are also constructors for random numbers\n",
        "\n",
        "# Uniform distribution\n",
        "a = torch.rand(1, 3)\n",
        "\n",
        "# Normal distribution\n",
        "b = torch.randn(3, 4)\n",
        "\n",
        "# There are also constructors that allow us to construct\n",
        "# a tensor according to the above constructors, but with\n",
        "# dimensions equal to another tensor.\n",
        "\n",
        "c = torch.zeros_like(a)\n",
        "d = torch.rand_like(c)\n",
        "\n",
        "print(f\"Tensor a: {a}\")\n",
        "print(f\"Tensor b: {b}\")\n",
        "print(f\"Tensor c: {c}\")\n",
        "print(f\"Tensor d: {d}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9XJq-P_MdJ5",
        "outputId": "ca70545a-4cc5-4133-b00b-d13224a8493d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([[0.4255, 0.0498, 0.3537]])\n",
            "Tensor b: tensor([[-0.6633, -2.7065, -0.8703, -0.6429],\n",
            "        [ 0.3941,  0.5269, -1.5429, -0.5554],\n",
            "        [ 1.0275,  0.8928,  0.3663,  1.9209]])\n",
            "Tensor c: tensor([[0., 0., 0.]])\n",
            "Tensor d: tensor([[0.3926, 0.5708, 0.8214]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reproducibility of random numbers to seed the  Random Number Generator (RNG) for all devices (both CPU and GPU)\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "import random\n",
        "random.seed(0)\n",
        "import numpy as np\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "zn-wMOceOYel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here, we define for you a function called set_seed that does the job for you!\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')"
      ],
      "metadata": {
        "id": "QNIrfZjpPiQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simplefun(seed=True, my_seed=None):\n",
        "  \"\"\"\n",
        "  Helper function to verify effectiveness of set_seed attribute\n",
        "\n",
        "  Args:\n",
        "    seed: Boolean\n",
        "      Specifies if seed value is provided or not\n",
        "    my_seed: Integer\n",
        "      Initializes seed to specified value\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  if seed:\n",
        "    set_seed(seed=my_seed)\n",
        "\n",
        "  # uniform distribution\n",
        "  a = torch.rand(1, 3)\n",
        "  # normal distribution\n",
        "  b = torch.randn(3, 4)\n",
        "\n",
        "  print(\"Tensor a: \", a)\n",
        "  print(\"Tensor b: \", b)\n"
      ],
      "metadata": {
        "id": "zdSwXuTFPtyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simplefun(seed=True, my_seed=0)  # Turn `seed` to `False` or change `my_seed`"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZy5CIWFP2UF",
        "outputId": "36360b6f-4b3c-49db-912f-6b78e0f9c2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 0 has been set.\n",
            "Tensor a:  tensor([[0.4963, 0.7682, 0.0885]])\n",
            "Tensor b:  tensor([[ 0.3643,  0.1344,  0.1642,  0.3058],\n",
            "        [ 0.2100,  0.9056,  0.6035,  0.8110],\n",
            "        [-0.0451,  0.8797,  1.0482, -0.0445]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(0, 10, step=1)\n",
        "b = np.arange(0, 10, step=1)\n",
        "\n",
        "c = torch.linspace(0, 5, steps=11)\n",
        "d = np.linspace(0, 5, num=11)\n",
        "\n",
        "print(f\"Tensor a: {a}\\n\")\n",
        "print(f\"Numpy array b: {b}\\n\")\n",
        "print(f\"Tensor c: {c}\\n\")\n",
        "print(f\"Numpy array d: {d}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJXIp7opQDYV",
        "outputId": "6ec9f474-f5c4-47b6-e17a-e7cf532a1676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "\n",
            "Numpy array b: [0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "Tensor c: tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,\n",
            "        4.5000, 5.0000])\n",
            "\n",
            "Numpy array d: [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Coding Exercise 2.1: Creating Tensors\n",
        "def tensor_creation(Z):\n",
        "  \"\"\"\n",
        "  A function that creates various tensors.\n",
        "\n",
        "  Args:\n",
        "    Z: numpy.ndarray\n",
        "      An array of shape (3,4)\n",
        "\n",
        "  Returns:\n",
        "    A : Tensor\n",
        "      20 by 21 tensor consisting of ones\n",
        "    B : Tensor\n",
        "      A tensor with elements equal to the elements of numpy array Z\n",
        "    C : Tensor\n",
        "      A tensor with the same number of elements as A but with values ∼U(0,1)\n",
        "    D : Tensor\n",
        "      A 1D tensor containing the even numbers between 4 and 40 inclusive.\n",
        "  \"\"\"\n",
        "  #################################################\n",
        "  ## TODO for students: fill in the missing code\n",
        "  ## from the first expression\n",
        "  ##raise NotImplementedError(\"Student exercise: say what they should have done\")\n",
        "  #################################################\n",
        "  A = torch.ones(20, 21)\n",
        "  B = torch.tensor(Z)\n",
        "  C = torch.rand_like(A)\n",
        "  D = torch.arange(4, 41, step=2)\n",
        "\n",
        "  return A, B, C, D\n",
        "\n",
        "\n",
        "# numpy array to copy later\n",
        "Z = np.vander([1, 2, 3], 4)\n",
        "\n",
        "# Uncomment below to check your function!\n",
        "A, B, C, D = tensor_creation(Z)\n",
        "print(f\"Tensor D: {D}\\n\")\n",
        "#checkExercise1(A, B, C, D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ezwpgDSMgM",
        "outputId": "2f38b75d-e5ae-4021-ed43-86b24b9c3de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor D: tensor([ 4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38,\n",
            "        40])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Section 2.2: Operations in PyTorch\n",
        "a = torch.ones(5, 3)\n",
        "b = torch.rand(5, 3)\n",
        "c = torch.empty(5, 3)\n",
        "d = torch.empty(5, 3)\n",
        "\n",
        "# this only works if c and d already exist\n",
        "torch.add(a, b, out=c)\n",
        "\n",
        "# Pointwise Multiplication of a and b\n",
        "torch.multiply(a, b, out=d)\n",
        "\n",
        "print(c)\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZbD4t4VgAJS",
        "outputId": "31b037e3-9192-4265-b627-febc57f3b60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7932, 1.2643, 1.5500],\n",
            "        [1.4938, 1.7337, 1.1532],\n",
            "        [1.5237, 1.9667, 1.8570],\n",
            "        [1.0044, 1.4247, 1.5047],\n",
            "        [1.3349, 1.1715, 1.1521]])\n",
            "tensor([[0.7932, 0.2643, 0.5500],\n",
            "        [0.4938, 0.7337, 0.1532],\n",
            "        [0.5237, 0.9667, 0.8570],\n",
            "        [0.0044, 0.4247, 0.5047],\n",
            "        [0.3349, 0.1715, 0.1521]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 4, 8])\n",
        "y = torch.tensor([1, 2, 3, 4])\n",
        "x + y, x - y, x * y, x / y, x**y  # The `**` is the exponentiation operator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAcc5qFEgdXz",
        "outputId": "69ca28a6-7b4f-4c6d-9af9-f441bcd0f264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 2,  4,  7, 12]),\n",
              " tensor([0, 0, 1, 4]),\n",
              " tensor([ 1,  4, 12, 32]),\n",
              " tensor([1.0000, 1.0000, 1.3333, 2.0000]),\n",
              " tensor([   1,    4,   64, 4096]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor Methods\n",
        "x = torch.rand(3, 3)\n",
        "print(x)\n",
        "print(\"\\n\")\n",
        "# sum() - note the axis is the axis you move across when summing\n",
        "print(f\"Sum of every element of x: {x.sum()}\")\n",
        "print(f\"Sum of the columns of x: {x.sum(axis=0)}\")\n",
        "print(f\"Sum of the rows of x: {x.sum(axis=1)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(f\"Mean value of all elements of x {x.mean()}\")\n",
        "print(f\"Mean values of the columns of x {x.mean(axis=0)}\")\n",
        "print(f\"Mean values of the rows of x {x.mean(axis=1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQT8XBYhhTFA",
        "outputId": "c58723d5-c0cd-4828-906f-f9ba0759c865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8322, 0.3381, 0.4678],\n",
            "        [0.6467, 0.1931, 0.5446],\n",
            "        [0.7974, 0.2077, 0.6455]])\n",
            "\n",
            "\n",
            "Sum of every element of x: 4.673100471496582\n",
            "Sum of the columns of x: tensor([2.2764, 0.7389, 1.6579])\n",
            "Sum of the rows of x: tensor([1.6382, 1.3844, 1.6505])\n",
            "\n",
            "\n",
            "Mean value of all elements of x 0.5192334055900574\n",
            "Mean values of the columns of x tensor([0.7588, 0.2463, 0.5526])\n",
            "Mean values of the rows of x tensor([0.5461, 0.4615, 0.5502])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Matrix Operations\n",
        "#Coding Exercise 2.2 : Simple tensor operations\n",
        "def simple_operations(a1: torch.Tensor, a2: torch.Tensor, a3: torch.Tensor):\n",
        "  \"\"\"\n",
        "  Helper function to demonstrate simple operations\n",
        "  i.e., Multiplication of tensor a1 with tensor a2 and then add it with tensor a3\n",
        "\n",
        "  Args:\n",
        "    a1: Torch tensor\n",
        "      Tensor of size ([2,2])\n",
        "    a2: Torch tensor\n",
        "      Tensor of size ([2,2])\n",
        "    a3: Torch tensor\n",
        "      Tensor of size ([2,2])\n",
        "\n",
        "  Returns:\n",
        "    answer: Torch tensor\n",
        "      Tensor of size ([2,2]) resulting from a1 multiplied with a2, added with a3\n",
        "  \"\"\"\n",
        "  ################################################\n",
        "  ## TODO for students:  complete the first computation using the argument matricies\n",
        "  #raise NotImplementedError(\"Student exercise: fill in the missing code to complete the operation\")\n",
        "  ################################################\n",
        "  #\n",
        "  answer = torch.matmul(a1,a2)+a3\n",
        "  return answer\n",
        "\n",
        "\n",
        "# Computing expression 1:\n",
        "\n",
        "# init our tensors\n",
        "a1 = torch.tensor([[2, 4], [5, 7]])\n",
        "a2 = torch.tensor([[1, 1], [2, 3]])\n",
        "a3 = torch.tensor([[10, 10], [12, 1]])\n",
        "## uncomment to test your function\n",
        "A = simple_operations(a1, a2, a3)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoN0TA8Qhm8c",
        "outputId": "e8893fac-a86a-41d9-9b13-9ccddc0c9101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 4],\n",
            "        [5, 7]])\n",
            "tensor([[20, 24],\n",
            "        [31, 27]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product(b1: torch.Tensor, b2: torch.Tensor):\n",
        "  ###############################################\n",
        "  ## TODO for students:  complete the first computation using the argument matricies\n",
        "  #raise NotImplementedError(\"Student exercise: fill in the missing code to complete the operation\")\n",
        "  ###############################################\n",
        "  \"\"\"\n",
        "  Helper function to demonstrate dot product operation\n",
        "  Dot product is an algebraic operation that takes two equal-length sequences\n",
        "  (usually coordinate vectors), and returns a single number.\n",
        "  Geometrically, it is the product of the Euclidean magnitudes of the\n",
        "  two vectors and the cosine of the angle between them.\n",
        "\n",
        "  Args:\n",
        "    b1: Torch tensor\n",
        "      Tensor of size ([3])\n",
        "    b2: Torch tensor\n",
        "      Tensor of size ([3])\n",
        "\n",
        "  Returns:\n",
        "    product: Tensor\n",
        "      Tensor of size ([1]) resulting from b1 scalar multiplied with b2\n",
        "  \"\"\"\n",
        "  # Use torch.dot() to compute the dot product of two tensors\n",
        "  product = torch.dot(b1, b2)\n",
        "  return product\n",
        "\n",
        "\n",
        "# Computing expression 2:\n",
        "b1 = torch.tensor([3, 5, 7])\n",
        "b2 = torch.tensor([2, 4, 8])\n",
        "## Uncomment to test your function\n",
        "b = dot_product(b1, b2)\n",
        "print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZxEiiLDn8Ki",
        "outputId": "84eb8a1b-82f4-4ffe-eba0-d965492465ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(82)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexing is also referred to as slicing.\n",
        "x = torch.arange(0, 10)\n",
        "print(x)\n",
        "print(x[-1])\n",
        "print(x[1:3])\n",
        "print(x[:-2])\n",
        "#When we have multidimensional tensors, indexing rules work the same way as NumPy\n",
        "# make a 5D tensor\n",
        "x = torch.rand(1, 2, 3, 4, 5)\n",
        "\n",
        "print(f\" shape of x[0]:{x[0].shape}\")\n",
        "print(f\" shape of x[0][0]:{x[0][0].shape}\")\n",
        "print(f\" shape of x[0][0][0]:{x[0][0][0].shape}\")\n",
        "\n",
        "#Flatten and reshape\n",
        "z = torch.arange(12).reshape(6, 2)\n",
        "print(f\"Original z: \\n {z}\")\n",
        "\n",
        "# 2D -> 1D\n",
        "z = z.flatten()\n",
        "print(f\"Flattened z: \\n {z}\")\n",
        "\n",
        "# and back to 2D\n",
        "z = z.reshape(3, 4)\n",
        "print(f\"Reshaped (3x4) z: \\n {z}\")\n",
        "\n",
        "#Squeezing tensors to deal with singleton dimensions. E.g., [1,10] or [256, 1, 3]\n",
        "#In order to compress tensors along their singleton dimensions we can use the .squeeze() method\n",
        "x = torch.randn(1, 10)\n",
        "# printing the zeroth element of the tensor will not give us the first number!\n",
        "\n",
        "print(x.shape)\n",
        "print(f\"x[0]: {x[0]}\")\n",
        "#Because of that pesky singleton dimension, x[0] gave us the first row instead!\n",
        "# Let's get rid of that singleton dimension and see what happens now\n",
        "x = x.squeeze(0)\n",
        "print(x.shape)\n",
        "print(f\"x[0]: {x[0]}\")\n",
        "# Adding singleton dimensions works a similar way, and is often used when tensors\n",
        "# being added need same number of dimensions\n",
        "\n",
        "y = torch.randn(5, 5)\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "\n",
        "# lets insert a singleton dimension\n",
        "y = y.unsqueeze(1)\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "\n",
        "# Permutation\n",
        "#we may be dealing with RGB images with dim [3×48×64]\n",
        "#, but our pipeline expects the colour dimension to be the last dimension, i.e., [48×64×3]\n",
        "# To get around this we can use the .permute() method.\n",
        "\n",
        "# `x` has dimensions [color,image_height,image_width]\n",
        "x = torch.rand(3, 48, 64)\n",
        "\n",
        "# We want to permute our tensor to be [ image_height , image_width , color ]\n",
        "x = x.permute(1, 2, 0)\n",
        "# permute(1,2,0) means:\n",
        "# The 0th dim of my new tensor = the 1st dim of my old tensor\n",
        "# The 1st dim of my new tensor = the 2nd\n",
        "# The 2nd dim of my new tensor = the 0th\n",
        "print(x.shape)\n",
        "\n",
        "# Concatenation\n",
        "#In this example, we concatenate two matrices along rows (axis 0, the first element of the shape)\n",
        "# vs. columns (axis 1, the second element of the shape).\n",
        "# Create two tensors of the same shape\n",
        "x = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
        "y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "\n",
        "# Concatenate along rows\n",
        "cat_rows = torch.cat((x, y), dim=0)\n",
        "\n",
        "# Concatenate along columns\n",
        "cat_cols = torch.cat((x, y), dim=1)\n",
        "\n",
        "# Printing outputs\n",
        "print('Concatenated by rows: shape{} \\n {}'.format(list(cat_rows.shape), cat_rows))\n",
        "print('\\n Concatenated by colums: shape{}  \\n {}'.format(list(cat_cols.shape), cat_cols))\n",
        "\n",
        "#Converting a tensor to a numpy.ndarray, or vice versa\n",
        "#This minor inconvenience is quite important: when you perform operations on the CPU or GPUs,\n",
        "#you do not want to halt computation, waiting to see whether the NumPy package of Python might\n",
        "#want to be doing something else with the same chunk of memory.\n",
        "x = torch.randn(5)\n",
        "print(f\"x: {x}  |  x type:  {x.type()}\")\n",
        "\n",
        "y = x.numpy()\n",
        "print(f\"y: {y}  |  y type:  {type(y)}\")\n",
        "\n",
        "z = torch.tensor(y)\n",
        "print(f\"z: {z}  |  z type:  {z.type()}\")\n",
        "\n",
        "#To convert a size-1 tensor to a Python scalar, we can invoke the item function or Python’s built-in functions.\n",
        "a = torch.tensor([3.5])\n",
        "a, a.item(), float(a), int(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Rumg_CRHaW",
        "outputId": "6b8c74e7-6086-4dca-980e-390581c38283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor(9)\n",
            "tensor([1, 2])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Coding Exercise 2.3: Manipulating Tensors\n",
        "def functionA(my_tensor1, my_tensor2):\n",
        "  \"\"\"\n",
        "  This function takes in two 2D tensors `my_tensor1` and `my_tensor2`\n",
        "  and returns the column sum of\n",
        "  `my_tensor1` multiplied by the sum of all the elmements of `my_tensor2`,\n",
        "  i.e., a scalar.\n",
        "\n",
        "  Args:\n",
        "    my_tensor1: torch.Tensor\n",
        "    my_tensor2: torch.Tensor\n",
        "\n",
        "  Returns:\n",
        "    output: torch.Tensor\n",
        "      The multiplication of the column sum of `my_tensor1` by the sum of\n",
        "      `my_tensor2`.\n",
        "  \"\"\"\n",
        "  # TODO multiplication the sum of the tensors\n",
        "  output = my_tensor1.sum(axis=0) * my_tensor2.sum()\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "def functionB(my_tensor):\n",
        "  \"\"\"\n",
        "  This function takes in a square matrix `my_tensor` and returns a 2D tensor\n",
        "  consisting of a flattened `my_tensor` with the index of each element\n",
        "  appended to this tensor in the row dimension.\n",
        "\n",
        "  Args:\n",
        "    my_tensor: torch.Tensor\n",
        "\n",
        "  Returns:\n",
        "    output: torch.Tensor\n",
        "      Concatenated tensor.\n",
        "  \"\"\"\n",
        "  # TODO flatten the tensor `my_tensor`\n",
        "  my_tensor = my_tensor.flatten()\n",
        "  # TODO create the idx tensor to be concatenated to `my_tensor`\n",
        "  idx_tensor = torch.arange(0, len(my_tensor))\n",
        "  # TODO concatenate the two tensors\n",
        "  output = torch.cat([idx_tensor.unsqueeze(1), my_tensor.unsqueeze(1)], axis=1)\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "def functionC(my_tensor1, my_tensor2):\n",
        "  \"\"\"\n",
        "  This function takes in two 2D tensors `my_tensor1` and `my_tensor2`.\n",
        "  If the dimensions allow it, it returns the\n",
        "  elementwise sum of `my_tensor1`-shaped `my_tensor2`, and `my_tensor2`;\n",
        "  else this function returns a 1D tensor that is the concatenation of the\n",
        "  two tensors.\n",
        "\n",
        "  Args:\n",
        "    my_tensor1: torch.Tensor\n",
        "    my_tensor2: torch.Tensor\n",
        "\n",
        "  Returns:\n",
        "    output: torch.Tensor\n",
        "      Concatenated tensor.\n",
        "  \"\"\"\n",
        "  # TODO check we can reshape `my_tensor2` into the shape of `my_tensor1`\n",
        "  if torch.numel(my_tensor1) == torch.numel(my_tensor2):\n",
        "    # TODO reshape `my_tensor2` into the shape of `my_tensor1`\n",
        "    my_tensor2 = my_tensor2.reshape(my_tensor1.shape)\n",
        "    # TODO sum the two tensors\n",
        "    output = my_tensor1 + my_tensor2\n",
        "  else:\n",
        "    # TODO flatten both tensors. -1 means remove that dimension\n",
        "    my_tensor1 = my_tensor1.reshape(1, -1)\n",
        "    my_tensor2 = my_tensor2.reshape(1, -1)\n",
        "    # TODO concatenate the two tensors in the correct dimension\n",
        "    output = torch.cat([my_tensor1, my_tensor2], axis=1).squeeze()\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "## Implement the functions above and then uncomment the following lines to test your code\n",
        "print(functionA(torch.tensor([[1, 1], [1, 1]]), torch.tensor([[1, 2, 3], [1, 2, 3]])))\n",
        "print(functionB(torch.tensor([[2, 3], [-1, 10]])))\n",
        "print(functionC(torch.tensor([[1, -1], [-1, 3]]), torch.tensor([[2, 3, 0, 2]])))\n",
        "print(functionC(torch.tensor([[1, -1], [-1, 3]]), torch.tensor([[2, 3, 0]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzHgvJOtUF3-",
        "outputId": "c359a774-e1ef-47e0-906e-1582663ce50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([24, 24])\n",
            "tensor([[ 0,  2],\n",
            "        [ 1,  3],\n",
            "        [ 2, -1],\n",
            "        [ 3, 10]])\n",
            "tensor([[ 3,  2],\n",
            "        [-1,  5]])\n",
            "tensor([ 1, -1, -1,  3,  2,  3,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Coding Exercise 2.4: Just how much faster are GPUs?\n",
        "#CPU or GPU specified by the parameter device\n",
        "dim = 10000\n",
        "iterations = 1\n",
        "def simpleFun(dim, device):\n",
        "  \"\"\"\n",
        "  Helper function to check device-compatiblity with computations\n",
        "\n",
        "  Args:\n",
        "    dim: Integer\n",
        "    device: String\n",
        "      \"cpu\" or \"cuda\"\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  # 2D tensor filled with uniform random numbers in [0,1), dim x dim\n",
        "  x = torch.rand(dim, dim).to(device)\n",
        "  # 2D tensor filled with uniform random numbers in [0,1), dim x dim\n",
        "  y = torch.rand_like(x).to(device)\n",
        "  # 2D tensor filled with the scalar value 2, dim x dim\n",
        "  z = 2*torch.ones(dim, dim).to(device)\n",
        "\n",
        "  # elementwise multiplication of x and y\n",
        "  a = x * y\n",
        "  # matrix multiplication of x and z\n",
        "  b = x @ z\n",
        "\n",
        "  del x\n",
        "  del y\n",
        "  del z\n",
        "  del a\n",
        "  del b\n",
        "\n",
        "\n",
        "## Implement the function above and uncomment the following lines to test your code\n",
        "timeFun(f=simpleFun, dim=dim, iterations=iterations)\n",
        "timeFun(f=simpleFun, dim=dim, iterations=iterations, device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "u8LyxYS_YrEF",
        "outputId": "021f2916-a79a-456a-c603-9687caf57df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-20abde049dd4>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m## Implement the function above and uncomment the following lines to test your code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtimeFun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimpleFun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mtimeFun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimpleFun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'timeFun' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2.5: Datasets and Dataloaders\n",
        "# Import dataset and dataloaders related packages\n",
        "# The torchvision package gives you easy access to many of the publicly available datasets.\n",
        "# the CIFAR10 dataset, which contains color images of 10 different classes, like vehicles and animals.\n",
        "# Creating an object of type datasets.CIFAR10 will automatically download and load all images from the dataset.\n",
        "# The resulting data structure can be treated as a list containing data samples and their corresponding labels.\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, Grayscale\n"
      ],
      "metadata": {
        "id": "IxSYBCODTGjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load the images from the CIFAR10 dataset\n",
        "cifar10_data = datasets.CIFAR10(\n",
        "    root=\"data\",  # path where the images will be stored\n",
        "    download=True,  # all images should be downloaded\n",
        "    transform=ToTensor()  # transform the images to tensors\n",
        "    )\n",
        "\n",
        "# Print the number of samples in the loaded dataset\n",
        "print(f\"Number of samples: {len(cifar10_data)}\")\n",
        "print(f\"Class names: {cifar10_data.classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KXqXmqqTzOe",
        "outputId": "416a9694-f3e9-4aa9-c2aa-27f69755306c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 34616138.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Number of samples: 50000\n",
            "Class names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sample\n",
        "random.seed(2021)\n",
        "image, label = cifar10_data[random.randint(0, len(cifar10_data))]\n",
        "#Color images are modeled as 3 dimensional tensors. The first dimension corresponds to the channels (C\n",
        "#) of the image (in this case we have RGB images). The second dimensions is the height (H\n",
        "#) of the image and the third is the width (W\n",
        "#). We can denote this image format as C×H×W\n",
        "print(f\"Label: {cifar10_data.classes[label]}\")\n",
        "print(f\"Image size: {image.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJgOa5npUKCs",
        "outputId": "61fe87b7-bfae-4476-fa6f-7e032c602e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: horse\n",
            "Image size: torch.Size([3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding Exercise 2.5: Display an image from the dataset\n",
        "# Let’s try to display the image using matplotlib.\n",
        "#  The imshow expects to have the image in a different format, i.e., C×H×W\n",
        "# You need to reorder the dimensions of the tensor using the permute method of the tensor\n",
        "# The size of the returned tensor remains the same as that of the original.\n",
        "\n",
        "# create a tensor of size 2 x 4\n",
        "input_var = torch.randn(2, 4)\n",
        "# print its size and the tensor\n",
        "print(input_var.size())\n",
        "print(input_var)\n",
        "\n",
        "# dimensions permuted\n",
        "input_var = input_var.permute(1, 0)\n",
        "# print its size and the permuted tensor\n",
        "print(input_var.size())\n",
        "print(input_var)\n",
        "\n",
        "# TODO: Uncomment the following line to see the error that arises from the current image format\n",
        "# TODO: Comment the above line and fix this code by reordering the tensor dimensions\n",
        "#plt.imshow(image)\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "19qvF1GiUnP8",
        "outputId": "40ab9f90-ec76-4667-ed1c-10f142a226fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "tensor([[-0.0770, -1.6534,  0.3634, -0.1355],\n",
            "        [ 0.9027, -1.3745, -0.4260,  0.7094]])\n",
            "torch.Size([4, 2])\n",
            "tensor([[-0.0770,  0.9027],\n",
            "        [-1.6534, -1.3745],\n",
            "        [ 0.3634, -0.4260],\n",
            "        [-0.1355,  0.7094]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the training samples\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        "    )\n",
        "\n",
        "# Load the test samples\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wITz7snQn00M",
        "outputId": "093ae23e-e42b-4fb9-8cd6-0c495869773c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "#  It is a wrapper around the Dataset that splits it into minibatches\n",
        "# (important for training the neural network) and makes the data iterable\n",
        "#  The shuffle argument is used to shuffle the order of the samples across the minibatches\n",
        "# Create dataloaders with\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "# Reproducibility: DataLoader will reseed workers following Randomness\n",
        "# in multi-process data loading algorithm. Use worker_init_fn() and a generator to preserve reproducibility\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  numpy.random.seed(worker_seed)\n",
        "  my_seed=random.seed(worker_seed)\n",
        "\n",
        "\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(my_seed)\n",
        "\n",
        "DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g_seed\n",
        "    )\n",
        "#Important: For the seed_worker to have an effect, num_workers should be 2 or more.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "7fiEtGz8r-n_",
        "outputId": "2921e102-7e96-4594-bd2c-215f8dcd47d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d50531a47616>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mg_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mg_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m DataLoader(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'my_seed' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the next batch\n",
        "batch_images, batch_labels = next(iter(train_dataloader))\n",
        "print('Batch size:', batch_images.shape)\n",
        "\n",
        "# Display the first image from the batch\n",
        "plt.imshow(batch_images[0].permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "hMyI5gvztMsN",
        "outputId": "fef9f144-ce77-4918-83a9-d5d41db66741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([64, 3, 32, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "# There are many predefined transformations in the torchvision.transforms package and you can also combine them using the Compose transform.\n",
        "# Coding Exercise 2.6: Load the CIFAR10 dataset as grayscale images\n",
        "def my_data_load():\n",
        "  \"\"\"\n",
        "  Function to load CIFAR10 data as grayscale images\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    data: DataFrame\n",
        "      CIFAR10 loaded Dataframe of shape (3309, 14)\n",
        "  \"\"\"\n",
        "  ## TODO Load the CIFAR10 data using a transform that converts the images to grayscale tensors\n",
        "  data = datasets.CIFAR10(root=\"data\", download=True,\n",
        "                          transform=Compose([ToTensor(), Grayscale()]))\n",
        "  # Display a random grayscale image\n",
        "  image, label = data[random.randint(0, len(data))]\n",
        "  plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "  plt.show()\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "#set_seed(seed=2021)\n",
        "## After implementing the above code, uncomment the following lines to test your code\n",
        "data = my_data_load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "XIzVVreQtUDx",
        "outputId": "10b004bc-c99c-4106-d5bd-de39238203b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3: Neural Networks\n",
        "# Creating a simple neural network model\n",
        "# Training the network\n",
        "# Visualizing the results of the network\n",
        "# Tweaking the network\n",
        "# Generate sample data-  load the data from the CSV file using the Pandas library\n",
        "# in Pandas  we can reference the columns directly by their names\n",
        "# Load the data from the CSV file in a Pandas DataFrame\n",
        "data = pd.read_csv(\"sample_data.csv\")\n",
        "\n",
        "# Create a 2D numpy array from the x0 and x1 columns\n",
        "X_orig = data[[\"x0\", \"x1\"]].to_numpy()\n",
        "\n",
        "# Create a 1D numpy array from the y column\n",
        "y_orig = data[\"y\"].to_numpy()\n",
        "\n",
        "# Print the sizes of the generated 2D points X and the corresponding labels Y\n",
        "print(f\"Size X:{X_orig.shape}\")\n",
        "print(f\"Size y:{y_orig.shape}\")\n",
        "\n",
        "# Visualize the dataset. The color of the points is determined by the labels `y_orig`.\n",
        "plt.scatter(X_orig[:, 0], X_orig[:, 1], s=40, c=y_orig)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "ZO0U3taluKfH",
        "outputId": "e8290b8a-5e36-4dc5-ba6e-7679926c2882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-18623a7fb746>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# in Pandas  we can reference the columns directly by their names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load the data from the CSV file in a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create a 2D numpy array from the x0 and x1 columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Data for PyTorch- convert everything into tensors.\n",
        "# Initialize the device variable\n",
        "DEVICE = set_device()\n",
        "\n",
        "# Convert the 2D points to a float32 tensor\n",
        "X = torch.tensor(X_orig, dtype=torch.float32)\n",
        "\n",
        "# Upload the tensor to the device\n",
        "X = X.to(DEVICE)\n",
        "\n",
        "print(f\"Size X:{X.shape}\")\n",
        "\n",
        "# Convert the labels to a long interger tensor\n",
        "y = torch.from_numpy(y_orig).type(torch.LongTensor)\n",
        "\n",
        "# Upload the tensor to the device\n",
        "y = y.to(DEVICE)\n",
        "\n",
        "print(f\"Size y:{y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "fO6HxGv4vXZa",
        "outputId": "394f9ff2-f998-4860-c030-c14c47ace186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4f287f84c13a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare Data for PyTorch- convert everything into tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Initialize the device variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert the 2D points to a float32 tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'set_device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3.2: Create a Simple Neural Network\n",
        "# Inherit from nn.Module - the base class for neural network modules provided by Pytorch\n",
        "# PyTorch provides a base class for all neural network modules called nn.Module\n",
        "\n",
        "class NaiveNet(nn.Module):\n",
        "  \"\"\"\n",
        "  NaiveNet architecture\n",
        "  Structure is as follows:\n",
        "  Linear Layer (2, 16) -> ReLU activation -> Linear Layer (16, 2)\n",
        "  \"\"\"\n",
        "  # Define the structure of your network\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Defines the NaiveNet structure by initialising following attributes\n",
        "    nn.Linear (2, 16):  Transformation from the input to the hidden layer\n",
        "    nn.ReLU: Activation function (ReLU) is a non-linearity which is widely used because it reduces computation.\n",
        "             The function returns 0 if it receives any negative input, but for any positive value x, it returns that value back.\n",
        "    nn.Linear (16, 2): Transformation from the hidden to the output layer\n",
        "\n",
        "    Args:\n",
        "      None\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    ## call superclass\n",
        "    super(NaiveNet, self).__init__()\n",
        "\n",
        "    # The network is defined as a sequence of operations\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(2, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 2),\n",
        "    )\n",
        "\n",
        "  # Specify the computations performed on the data\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Defines the forward pass through the above defined structure\n",
        "\n",
        "    Args:\n",
        "      x: torch.Tensor\n",
        "        Input tensor of size ([3])\n",
        "\n",
        "    Returns:\n",
        "      layers: nn.module\n",
        "        Initialised Layers in order to re-use the same layer for each forward pass of data you make.\n",
        "    \"\"\"\n",
        "    # Pass the data through the layers\n",
        "    return self.layers(x)\n",
        "\n",
        "  # Choose the most likely label predicted by the network\n",
        "  def predict(self, x):\n",
        "    \"\"\"\n",
        "    Performs the prediction task of the network\n",
        "\n",
        "    Args:\n",
        "      x: torch.Tensor\n",
        "        Input tensor of size ([3])\n",
        "\n",
        "    Returns:\n",
        "      Most likely class i.e., Label with the highest score\n",
        "    \"\"\"\n",
        "    # Pass the data through the networks\n",
        "    output = self.forward(x)\n",
        "\n",
        "    # Choose the label with the highest score\n",
        "    return torch.argmax(output, 1)\n",
        "\n",
        "  # Train the neural network (will be implemented later)\n",
        "  def train(self, X, y):\n",
        "    \"\"\"\n",
        "    Training the Neural Network\n",
        "\n",
        "    Args:\n",
        "      X: torch.Tensor\n",
        "        Input data\n",
        "      y: torch.Tensor\n",
        "        Class Labels/Targets\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "opd2AFRXOcbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that your network works\n",
        "# Create an instance of your model and visualize it\n",
        "# Create new NaiveNet and transfer it to the device\n",
        "model = NaiveNet()\n",
        "#.to(DEVICE)\n",
        "\n",
        "# Print the structure of the network\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd-ltFl-8Ken",
        "outputId": "3d7f02ae-2390-4220-f9c2-cba9c715d0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaiveNet(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding Exercise 3.2: Classify some samples\n",
        "## Get the samples\n",
        "X_samples = X[0:5]\n",
        "print(\"Sample input:\\n\", X_samples)\n",
        "\n",
        "## Do a forward pass of the network\n",
        "output = model.forward(X_samples)\n",
        "print(\"\\nNetwork output:\\n\", output)\n",
        "\n",
        "## Predict the label of each point\n",
        "y_predicted = model.predict(X_samples)\n",
        "print(\"\\nPredicted labels:\\n\", y_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "8nxJ5bR48xV7",
        "outputId": "650d1197-93a8-44cc-95db-12cb29ea8126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d4bf4da6cf17>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Coding Exercise 3.2: Classify some samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## Get the samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample input:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3.3: Train Your Neural Network\n",
        "# Implement the train function given a training dataset X and correcsponding labels y\n",
        "def train(model, X, y):\n",
        "  \"\"\"\n",
        "    Training the Neural Network\n",
        "\n",
        "    Args:\n",
        "      X: torch.Tensor\n",
        "        Input data\n",
        "      y: torch.Tensor\n",
        "        Class Labels/Targets\n",
        "\n",
        "    Returns:\n",
        "      losses: Float\n",
        "        Cross Entropy Loss; Cross-entropy builds upon the idea of entropy\n",
        "        from information theory and calculates the number of bits required\n",
        "        to represent or transmit an average event from one distribution\n",
        "        compared to another distribution.\n",
        "    \"\"\"\n",
        "  # The Cross Entropy Loss is suitable for classification problems\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Create an optimizer (Stochastic Gradient Descent) that will be used to train the network\n",
        "  learning_rate = 1e-2\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Number of epochs\n",
        "  epochs = 15000\n",
        "\n",
        "  # List of losses for visualization\n",
        "  losses = []\n",
        "\n",
        "  for i in range(epochs):\n",
        "    # Pass the data through the network and compute the loss\n",
        "    # We'll use the whole dataset during the training instead of using batches\n",
        "    # in to order to keep the code simple for now.\n",
        "    y_logits = model.forward(X)\n",
        "    loss = loss_function(y_logits, y)\n",
        "\n",
        "    # Clear the previous gradients and compute the new ones\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Adapt the weights of the network\n",
        "    optimizer.step()\n",
        "\n",
        "    # Store the loss\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Print the results at every 1000th epoch\n",
        "    if i % 1000 == 0:\n",
        "      print(f\"Epoch {i} loss is {loss.item()}\")\n",
        "\n",
        "      plot_decision_boundary(model, X, y, DEVICE)\n",
        "      plt.savefig('frames/{:05d}.png'.format(i))\n",
        "\n",
        "  return losses\n",
        "\n",
        "\n",
        "# Create a new network instance a train it\n",
        "model = NaiveNet().to(DEVICE)\n",
        "losses = train(model, X, y)"
      ],
      "metadata": {
        "id": "vbNcK_vLswiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the loss during the training to see how it reduces and converges\n",
        "plt.plot(np.linspace(1, len(losses), len(losses)), losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "Text(0, 0.5, 'Loss')"
      ],
      "metadata": {
        "id": "2U62RhQOPcIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the training process\n",
        "# @title Visualize the training process\n",
        "# @markdown Execute this cell!\n",
        "!pip install imageio --quiet\n",
        "!pip install pathlib --quiet\n",
        "\n",
        "import imageio.v2 as imageio\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# Make a list with all images\n",
        "images = []\n",
        "for i in range(10):\n",
        "  filename = Path(\"frames/0\"+str(i)+\"000.png\")\n",
        "  images.append(imageio.imread(filename))\n",
        "# Save the gif\n",
        "imageio.mimsave('frames/movie.gif', images)\n",
        "gifPath = Path(\"frames/movie.gif\")\n",
        "with open(gifPath,'rb') as f:\n",
        "  display(Image(data=f.read(), format='png'))"
      ],
      "metadata": {
        "id": "vEmz5I4LPsJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Typically:\n",
        "1. Training for longer number of epochs tends to increase performance (but early stopping also works in some cases).\n",
        "2. Increased size of hidden layers aka width increases capacity leading to double descent.\n",
        "3. Increasing number of hidden layers aka depth typically makes the network more expressive (but networks that're very deep overfit).\n",
        "\"\"\";"
      ],
      "metadata": {
        "id": "W-FQCGehStjj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}